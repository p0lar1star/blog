# 推荐模型构建流程

Data(数据)->Features(特征)->ML Algorithm(机器学习算法)->Prediction Output(预测输出)

**推荐模型的构建：数据采集->特征工程->机器学习算法->预测->评估**

-   数据清洗/数据处理

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041808649.png)

-   数据来源

    **前端“埋点”——JS代码**，比如点击某一个按钮，调用相应的接口，把当前的时间，用户的id还有当前的行为及对应的位置（在哪个页面发生的行为）交给后端，后端记下来

    -   显性数据（显性评分：直接评价的数据）
        -   Rating 打分：好还是不好，直接反映
        -   Comments 评论/评价
    -   隐形数据（大多数时候没有直接评价的数据）
        -    Order history 历史订单
        -    Cart events 加购物车，感兴趣
        -    Page views 页面浏览——把东西展示给用户，他没看，说明不感兴趣
        -    Click-thru 点击
        -    Search log 搜索记录

-   数据量/数据能否满足要求

-   特征工程![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041808493.png)

-   从数据中筛选特征

    一个给定的商品，可能被拥有类似品味或需求的用户购买

    使用用户行为数据描述商品

    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041808487.png)

    **1 .25表示用户对物品的评分，1号用户对17号物品的评分是1**

-   用数据表示特征

    将所有用户行为合并在一起 ，形成一个user-item 矩阵

    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810457.png)

**协同过滤，要把用户对物品的评分处理成上述形式——矩阵**

假设用户很多，矩阵比较满（非稀疏矩阵），竖着一列就是用户的向量，计算相似度可用余弦相似度或皮尔逊系数，判断用户相似或者不相似，或矩阵分解

1.选择合适的算法

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041808620.png)

2.产生推荐结果

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041808576.png)

### 推荐模型构建流程之总结：四个步骤

**1.数据收集：**

分成显性评分和隐形数据，显性评分+隐性数据

**2.特征工程：**

如果是协同过滤，要创建用户-物品的评分矩阵

如果是基于内容，即基于文本描述（比如iPhone 13土豪金256G和iPhone max是一样的东西或类似的东西吗）

怎么判断相似？要用到（中文）分词（jieba）->tf-idf（用来提取特征词，算出每个词的权重）->词向量（word2vec）用来计算相似性

**3.训练模型：**

协同过滤：kNN，矩阵分解

**4.评估，模型上线**

# 最经典的推荐算法：协同过滤推荐算法（Collaborative Filtering）

算法思想：**物以类聚，人以群分**

有**基于内存的协同过滤**、**基于模型的协同过滤**和混合模型

基本的协同过滤推荐算法基于以下假设：

-   “跟你喜好**相似的人**喜欢的东西你也很有可能喜欢” ：基于用户的协同过滤推荐（User-based CF）
-   “跟你喜欢的东西**相似的东西**你也很有可能喜欢 ”：基于物品的协同过滤推荐（Item-based CF）

## 1.步骤

实现协同过滤推荐有以下几个步骤：

1.  **找出最相似的人或物品：TOP-N相似的人或物品**
    通过计算两两的相似度来进行排序，即可找出TOP-N相似的人或物品
2.  **根据相似的人或物品产生推荐结果**
    利用TOP-N结果生成初始推荐结果，然后过滤掉用户已经有过记录的物品或明确表示不感兴趣的物品

以下是一个简单的示例，数据集相当于一个用户对物品的购买记录表：打勾表示用户对物品的有购买记录

关于相似度计算这里先用一个简单的思想：如有两个同学X和Y，X同学爱好[足球、篮球、乒乓球]，Y同学爱好[网球、足球、篮球、羽毛球]，可见他们的共同爱好有2个，那么他们的相似度可以用：2/3 * 2/4 = 1/3 ≈ 0.33 来表示。

## 2.User-Based CF

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809804.png)

## 3.Item-Based CF

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809886.png)

## 4.总结：物以类聚人以群分

**做协同过滤，第一步就是特征工程把用户-物品的评分矩阵创建出来**

**做不出来，就没法协同过滤，如果是新系统，没有大量数据和用户行为，搞不出矩阵，不行。或者搞出来也是稀疏的，效果不好。**

基于用户的协同过滤：

1.给用户A找到最相似的N个用户

2.N个用户消费过哪些物品

3.N个用户消费过的物品减去A用户消费过的就是推荐结果

基于物品的协同过滤：

1.给物品A找到最相似的N个物品

2.A用户消费记录或浏览记录等等中找到这些物品的相似物品

3.从这些相似物品中减去A用户消费过的就是推荐结果

# 相似度计算(Similarity Calculation)

-   相似度的计算方法

    -   数据分类
        -   实数值(物品评分情况)
        -   布尔值(用户的行为如，是否点击 是否收藏，1010这样的布尔值)
    -   欧氏距离，衡量这两个点之间的距离，不适用于布尔向量之间
        E(p,q)=∑i=1n(pi−qi)2
         欧氏距离的值非负, 最大值正无穷, 通常计算相似度的结果希望是[-1,1]或[0,1]之间,一般可以使用如下转化公式:11+E(p,q)

-   杰卡德相似度&余弦相似度&皮尔逊相关系数

    -   余弦相似度
        -   度量的是两个向量之间的夹角, 用夹角的余弦值来度量相似的情况
        -   两个向量的夹角为0余弦值为1, 当夹角为90度是余弦值为0,为180度是余弦值为-1
        -   余弦相似度在度量文本相似度, 用户相似度,物品相似度的时候较为常用
        -   余弦相似度的特点, **与向量长度无关**，余弦相似度计算要对向量长度归一化, 两个向量只要方向一致,无论程度强弱, 都可以视为’相似’
        -   正因为与向量长度无关，计算时可能会面临这个问题：假设xy坐标分别代表两用户对两部不同电影的评分，一个人为两部电影都还可以看，给出了5和8的评分，一个认为两部电影都是烂片，给出了0.5和1的差评，(5,8)和(0.5,1)是两个相距非常远的点。但计算余弦相似度时可能会认为这两用户很相似。
    -   皮尔逊相关系数Pearson
        -   **实际上也是一种余弦相似度**, 不过**先对向量做了中心化**, 向量a b 各自减去向量的均值后, 再计算余弦相似度（考虑了长度，一般用这个）
        -   皮尔逊相似度计算结果在-1,1之间 -1表示负相关, 1表示正相关
        -   度量两个变量是不是同增同减
        -   皮尔逊相关系数度量的是两个变量的变化趋势是否一致, **不适合计算布尔值向量之间的相关度**
    -   杰卡德相似度 Jaccard
        -   两个集合的交集元素个数在并集中所占的比例, 非常适用于布尔向量表示
        -   分子是两个布尔向量做点积计算, 得到的就是交集元素的个数
        -   分母是两个布尔向量做或运算, 再求元素和
    -   余弦相似度适合用户评分数据(实数值), 杰卡德相似度适用于隐式反馈数据(0,1布尔值)(是否收藏,是否点击,是否加购物车)

    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809761.png)

-   余弦相似度
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809410.png)

-   皮尔逊相关系数
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809791.png)
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809401.png)

-   计算出用户1和其它用户之间的相似度
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809812.png)

-   按照相似度大小排序, K近邻 如K取4:
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809635.png)

-   取出近邻用户的购物清单
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809683.png)

-   去除用户1已经购买过的商品
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809637.png)

-   在剩余的物品中根据评分排序
    ![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809891.png)

-   物品相似度计算

    -   余弦相似度对绝对值大小不敏感带来的问题
        -   用户A对两部电影评分分别是1分和2分, 用户B对同样这两部电影进行评分是4分,5分 用余弦相似度计算,两个用户的相似度达到0.98
        -   可以采用改进的余弦相似度, 先计算向量每个维度上的均值, 然后每个向量在各个维度上都减去均值后,在计算余弦相似度, 用调整的余弦相似度计算得到的相似度是-0.1

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810828.png)

物品相似度计算案例

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809790.png)

找出物品1的相似商品

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810124.png)

选择最近似的物品

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809955.png)

基于用户与物品的协同过滤比较

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809874.png)

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809570.png)

# 基于内存的协同过滤

## 1.协同过滤推荐算法代码

构建数据集：

```python
users = ["User1", "User2", "User3", "User4", "User5"]
items = ["Item A", "Item B", "Item C", "Item D", "Item E"]
# 构建数据集
datasets = [
    ["buy",None,"buy","buy",None],
    ["buy",None,None,"buy","buy"],
    ["buy",None,"buy",None,None],
    [None,"buy",None,"buy","buy"],
    ["buy","buy","buy",None,"buy"],
]
```

计算时我们数据通常都需要对数据进行处理，或者编码，目的是为了便于我们对数据进行运算处理，比如这里是比较简单的情形，我们用1、0分别来表示用户的是否购买过该物品，则我们的数据集其实应该是这样的：

```python
users = ["User1", "User2", "User3", "User4", "User5"]
items = ["Item A", "Item B", "Item C", "Item D", "Item E"]
# 用户购买记录数据集
datasets = [
    [1,0,1,1,0],
    [1,0,0,1,1],
    [1,0,1,0,0],
    [0,1,0,1,1],
    [1,1,1,0,1],
]
import pandas as pd

df = pd.DataFrame(datasets,
                  columns=items,
                  index=users)
print(df)
```

进行相似度的计算，不过对于相似度的计算其实是有很多专门的相似度计算方法的，比如余弦相似度、皮尔逊相关系数、杰卡德相似度等等。选择使用杰卡德相似系数[0,1]

```python
# 直接计算某两项的杰卡德相似系数
from sklearn.metrics import jaccard_similarity_score
# 计算Item A 和Item B的相似度
print(jaccard_similarity_score(df["Item A"], df["Item B"]))

# 计算所有的数据两两的杰卡德相似系数
from sklearn.metrics.pairwise import pairwise_distances
# 计算用户间相似度
user_similar = 1 - pairwise_distances(df, metric="jaccard")
user_similar = pd.DataFrame(user_similar, columns=users, index=users)
print("用户之间的两两相似度：")
print(user_similar)

# 计算物品间相似度
item_similar = 1 - pairwise_distances(df.T, metric="jaccard")
item_similar = pd.DataFrame(item_similar, columns=items, index=items)
print("物品之间的两两相似度：")
print(item_similar)
```

有了两两的相似度，接下来筛选TOP-N相似结果，并进行推荐

User-Based CF

```python
import pandas as pd
import numpy as np
from pprint import pprint

users = ["User1", "User2", "User3", "User4", "User5"]
items = ["Item A", "Item B", "Item C", "Item D", "Item E"]
# 用户购买记录数据集
datasets = [
    [1,0,1,1,0],
    [1,0,0,1,1],
    [1,0,1,0,0],
    [0,1,0,1,1],
    [1,1,1,0,1],
]

df = pd.DataFrame(datasets,
                  columns=items,
                  index=users)

# 计算所有的数据两两的杰卡德相似系数
from sklearn.metrics.pairwise import pairwise_distances
# 计算用户间相似度
user_similar = 1 - pairwise_distances(df, metric="jaccard")
user_similar = pd.DataFrame(user_similar, columns=users, index=users)
print("用户之间的两两相似度：")
print(user_similar)

topN_users = {}
# 遍历每一行数据
for i in user_similar.index:
    # 取出每一列数据，并删除自身，然后排序数据
    _df = user_similar.loc[i].drop([i])
    _df_sorted = _df.sort_values(ascending=False)

    top2 = list(_df_sorted.index[:2])
    topN_users[i] = top2

print("Top2相似用户：")
pprint(topN_users)

rs_results = {}
# 构建推荐结果
for user, sim_users in topN_users.items():
    rs_result = set()    # 存储推荐结果
    for sim_user in sim_users:
        # 构建初始的推荐结果
        rs_result = rs_result.union(set(df.ix[sim_user].replace(0,np.nan).dropna().index))
    # 过滤掉已经购买过的物品
    rs_result -= set(df.ix[user].replace(0,np.nan).dropna().index)
    rs_results[user] = rs_result
print("最终推荐结果：")
pprint(rs_results)
```

Item-Based CF

```python
import pandas as pd
import numpy as np
from pprint import pprint

users = ["User1", "User2", "User3", "User4", "User5"]
items = ["Item A", "Item B", "Item C", "Item D", "Item E"]
# 用户购买记录数据集
datasets = [
    [1,0,1,1,0],
    [1,0,0,1,1],
    [1,0,1,0,0],
    [0,1,0,1,1],
    [1,1,1,0,1],
]

df = pd.DataFrame(datasets,
                  columns=items,
                  index=users)

# 计算所有的数据两两的杰卡德相似系数
from sklearn.metrics.pairwise import pairwise_distances
# 计算物品间相似度
item_similar = 1 - pairwise_distances(df.T.values, metric="jaccard")
item_similar = pd.DataFrame(item_similar, columns=items, index=items)
print("物品之间的两两相似度：")
print(item_similar)

topN_items = {}
# 遍历每一行数据
for i in item_similar.index:
    # 取出每一列数据，并删除自身，然后排序数据
    _df = item_similar.loc[i].drop([i])
    _df_sorted = _df.sort_values(ascending=False)

    top2 = list(_df_sorted.index[:2])
    topN_items[i] = top2

print("Top2相似物品：")
pprint(topN_items)

rs_results = {}
# 构建推荐结果
for user in df.index:    # 遍历所有用户
    rs_result = set()
    for item in df.ix[user].replace(0,np.nan).dropna().index:   # 取出每个用户当前已购物品列表
        # 根据每个物品找出最相似的TOP-N物品，构建初始推荐结果
        rs_result = rs_result.union(topN_items[item])
    # 过滤掉用户已购的物品
    rs_result -= set(df.ix[user].replace(0,np.nan).dropna().index)
    # 添加到结果中
    rs_results[user] = rs_result

print("最终推荐结果：")
pprint(rs_results)
```

**关于协同过滤推荐算法使用的数据集**
在前面的demo中，我们只是使用用户对物品的一个购买记录，类似也可以是比如浏览点击记录、收听记录等等。这样数据我们**预测的结果其实相当于是在预测用户是否对某物品感兴趣，对于喜好程度不能很好的预测**（只有是或否，区分度不高）。

因此**在协同过滤推荐算法中其实会更多的利用用户对物品的“评分”数据来进行预测**，通过评分数据集，我们可以预测用户对于他没有评分过的物品的评分。其实现原理和思想和都是一样的，只是使用的数据集是用户-物品的评分数据（可以更加细致地体现出用户对物品的喜好程度）。

**关于用户-物品评分矩阵**
**用户-物品的评分矩阵，根据评分矩阵的稀疏程度会有不同的解决方案**

**稠密评分矩阵(可直接使用皮尔逊相似度计算)**

![image-20220312215030439](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809096.png)

**稀疏评分矩阵(需要进行矩阵分解)**

![image-20220312215043388](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810793.png)

下面先介绍稠密评分矩阵的处理，稀疏矩阵的处理会相对复杂一些，后面再介绍

## 2.使用协同过滤推荐算法对用户进行评分预测

### 代码

**目的：预测用户1对物品E的评分**

构建数据集：对于缺失的部分我们需要保留为None，如果设置为0那么会被当作评分值为0去对待

```python
users = ["User1", "User2", "User3", "User4", "User5"]
items = ["Item A", "Item B", "Item C", "Item D", "Item E"]
# 用户购买记录数据集
datasets = [
    [5,3,4,4,None],
    [3,1,2,3,3],
    [4,3,4,3,5],
    [3,3,1,5,4],
    [1,5,5,2,1],
]
```

计算相似度：对于评分数据这里我们采用皮尔逊相关系数[-1,1]来计算，-1表示强负相关，+1表示强正相关

>   pandas中corr方法可直接用于计算皮尔逊相关系数

```python
df = pd.DataFrame(datasets,
                  columns=items,
                  index=users)

print("用户之间的两两相似度：")
# 直接计算皮尔逊相关系数
# 默认是按列进行计算，因此如果计算用户间的相似度，当前需要进行转置
user_similar = df.T.corr()
print(user_similar.round(4))

print("物品之间的两两相似度：")
item_similar = df.corr()
print(item_similar.round(4))
```

```python
# 运行结果：
用户之间的两两相似度：
        User1   User2   User3   User4   User5
User1  1.0000  0.8528  0.7071  0.0000 -0.7921
User2  0.8528  1.0000  0.4677  0.4900 -0.9001
User3  0.7071  0.4677  1.0000 -0.1612 -0.4666
User4  0.0000  0.4900 -0.1612  1.0000 -0.6415
User5 -0.7921 -0.9001 -0.4666 -0.6415  1.0000
物品之间的两两相似度：
        Item A  Item B  Item C  Item D  Item E
Item A  1.0000 -0.4767 -0.1231  0.5322  0.9695
Item B -0.4767  1.0000  0.6455 -0.3101 -0.4781
Item C -0.1231  0.6455  1.0000 -0.7206 -0.4276
Item D  0.5322 -0.3101 -0.7206  1.0000  0.5817
Item E  0.9695 -0.4781 -0.4276  0.5817  1.0000
```

可以看到与用户1最相似的是用户2和用户3；与物品A最相似的物品分别是物品E和物品D。

**注意：**我们在预测评分时，往往是通过与其有正相关的用户或物品进行预测，如果不存在正相关的情况，那么将无法做出预测。这一点尤其是在稀疏评分矩阵中尤为常见，因为稀疏评分矩阵中很难得出正相关系数。

### 如何利用相似度来做评分预测

**User-Based CF 评分预测：使用用户间的相似度进行预测**

关于评分预测的方法也有比较多的方案，下面介绍一种效果比较好的方案，**利用用户相似度和相似用户的评价来加权平均**，该方案考虑了**用户本身的评分评分以及近邻用户的加权平均相似度打分**来进行预测：pred(u,i)=r^ui=∑v∈Usim(u,v)∗rvi∑v∈U|sim(u,v)|

用户u和v之间的相似度乘上消费过这个商品的用户v对此商品的评分（皮尔逊相关系数）

![image-20220312214949203](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809131.png)

我们要预测用户1对物品E的评分，那么可以根据与用户1最近邻的用户2和用户3进行预测，计算如下：
pred(u1,i5)=0.85∗3+0.71∗50.85+0.71=3.91（用户2和3对该物品的评分分别是3和5）

![image-20220312215004010](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809923.png)

最终预测出用户1对物品5的评分为3.91

**Item-Based CF 评分预测：使用物品间的相似度进行预测**

这里利用物品相似度预测的计算同上，同样考虑了用户自身的平均打分因素，结合预测物品与相似物品的加权平均相似度打分进行来进行预测
pred(u,i)=r^ui=∑j∈Iratedsim(i,j)∗ruj∑j∈Iratedsim(i,j)

![image-20220312215526835](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810133.png)

我们要预测用户1对物品E的评分，那么可以根据与物品E最近邻的物品A和物品D进行预测，计算如下：
pred(u1,i5)=0.97∗5+0.58∗40.97+0.58=4.63

![image-20220312215537005](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809362.png)

对比可见，User-Based CF预测评分和Item-Based CF的评分结果也是存在差异的，因为严格意义上他们其实应当属于两种不同的推荐算法，各自在不同的领域不同场景下，都会比另一种的效果更佳，但**具体哪一种更佳，必须经过合理的效果评估**，因此在实现推荐系统时这两种算法往往都是需要去实现的，然后对产生的推荐效果进行评估分析选出更优方案。

### 总结

**如果买/没买 点/没点数据 0/1适合使用杰卡德相似度**

**一般用品分区做协同过滤，推荐使用皮尔逊相关系数**

实践中，基于用户和基于物品的协同过滤都做，对比效果

# 基于模型的协同过滤

**利用皮尔逊去算，要求评分矩阵是稠密的**

**但在真实的互联网产品中，稠密的可能性很低**

头条，没日没夜的刷，也不可能把所有的文章都刷一遍

淘宝，不可能把所有东西都买一遍

假设应用有一千万个用户，有十亿件商品，这么大的矩阵，大多数用户撑死就买几千件商品，99.99%都是空的，是一个超级稀疏的矩阵。

之前的方法没有太多关于机器学习的方法，矩阵列出来，计算相似度，用到的只有KNN

思想

-   通过机器学习算法，在数据中找出模式，并将用户与物品间的互动方式模式化
-   基于模型的协同过滤方式是构建协同过滤更高级的算法

近邻模型的问题

-   物品之间存在相关性, 信息量并不随着向量维度增加而线性增加
-   矩阵元素稀疏, 计算结果不稳定,增减一个向量维度, 导致近邻结果差异很大的情况存在

算法分类，都是基于模型的方法

-   基于图的模型
-   **基于矩阵分解的方法**

## 1.基于图的模型

基于邻域的模型看做基于图的模型的简单形式

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809447.png)

原理

-   将用户的行为数据表示为二分图

-   基于二分图为用户进行推荐

-   根据两个顶点之间的路径数、路径长度和经过的顶点数来评价两个顶点的相关性

-   **剩余内容不作详细介绍**

    **路径数越多，路径长度越短，经过的顶点数月少的两个顶点，相关性越高**

## 2.基于矩阵分解的模型（降维）

原理

-   根据用户与物品的潜在表现，我们就可以预测用户对未评分的物品的喜爱程度
-   把原来的大矩阵, 近似分解成两个小矩阵的乘积, 在实际推荐计算时不再使用大矩阵, 而是使用分解得到的两个小矩阵
-   用户-物品评分矩阵A是M X N维, 即一共有M个用户, n个物品 我们选一个很小的数 K **(K<< M, K<< N)**，K可以理解成会影响到用户对物品评分的特征。
-   通过计算得到两个矩阵U V U是M * K矩阵 , 矩阵V是 N * K
    $U_{m*k} V^{T}_{n*k} 约等于 A_{m*n}$
    类似这样的计算过程就是矩阵分解

基于矩阵分解的方法

ALS交替最小二乘

-   ALS-WR(加权正则化交替最小二乘法): alternating-least-squares with weighted-λ –regularization
-   将用户(user)对商品(item)的评分矩阵分解为两个矩阵：**一个是用户对商品隐含特征的偏好矩阵，另一个是商品所包含的隐含特征的矩阵。**在这个矩阵分解的过程中，评分缺失项得到了填充，也就是说我们可以基于这个填充的评分来给用户做商品推荐了。

SVD奇异值分解矩阵

ALS方法

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809052.png)

ALS的矩阵分解算法常应用于推荐系统中，将用户(user)对商品(item)的评分矩阵，分解为用户对商品隐含特征的偏好矩阵，和商品在隐含特征上的映射矩阵。

与传统的矩阵分解SVD方法来分解矩阵R(R∈ℝm×n)不同的是，ALS(alternating least squares)希望找到两个低维矩阵，以 R̃ =XY 来逼近矩阵R，其中 ，X∈ℝm×d，Y∈ℝd×n，这样，将问题的复杂度由O(m*n)转换为O((m+n)*d)。

计算X和Y过程：首先用一个小于1的随机数初始化Y，并根据公式求X，此时就可以得到初始的XY矩阵了，根据平方差和得到的X，重新计算并覆盖Y，计算差平方和，反复进行以上两步的计算，直到差平方和小于一个预设的数，或者迭代次数满足要求则停止

## 3.总结：协同过滤之基于模型的算法

1.用户-物品矩阵比较稀疏的时候，直接去取物品向量或用户向量计算相似度，不太适合

2.基于模型的方法可以解决用户-物品矩阵比较稀疏的问题

3.矩阵分解

①把大的矩阵拆成两个小的：用户矩阵和物品矩阵

②大矩阵 约等于 用户矩阵乘物品矩阵

③使用als 交替最小二乘法来优化

④从优化之后的用户矩阵/物品矩阵中取出用户向量/物品向量

⑤用户向量点乘物品向量 得到最终评分的预测

# 推荐系统评估

好的推荐系统可以实现用户, 服务提供方, 内容提供方的共赢
![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809480.png)

## 1.显示反馈和隐式反馈

|          | 显式反馈                       | 隐式反馈                 |
| -------- | ------------------------------ | ------------------------ |
| 例子     | 电影/书籍评分 是否喜欢这个推荐 | 播放/点击 评论 下载 购买 |
| 准确性   | 高                             | 低                       |
| 数量     | 少                             | 多                       |
| 获取成本 | 高                             | 低                       |

显示反馈并不那么容易获取：可能你一开始还会想着好好评价，到后来就习惯性五星好评了

隐式反馈，需要我们“埋点”，在播放、点击、购买等接口处埋点以采集用户行为数据，并规定每种行为多少分（赋权）至于效果好不好，实践才知道

## 2.常用评估指标

• 准确性 • 信任度
• 满意度 • 实时性
• 覆盖率 • 鲁棒性
• 多样性 • 可扩展性
• 新颖性 • 商业⽬标
• 惊喜度 • ⽤户留存

### 准确性 (理论角度) 

#### 评分预测之RMSE MAE

RMSE（Root Mean Squard Error）均方根误差。

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810123.png)

就是MSE开个根号

MSE （Mean Squared Error）叫做均方误差。

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809731.png)

这里的y是测试集上的。

用 真实值-预测值 然后平方之后求和平均。

#### **召回率与精确率**

适用于**topN推荐**，按照**点没点击、选没选**来评估的时候，采用准确率和召回率进行评估

实际上非常简单，**精确率**是针对我们**预测结果**而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是

![image-20220314034803894](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810564.png)
而**召回率**是针对我们原来的**样本**而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。
![image-20220314034823248](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809436.png)

>   假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本，系统查找出50个，其中只有40个是真正的正样本，计算上述各指标。

-   TP: 将正类预测为正类数  40
-   FN: 将正类预测为负类数  20
-   FP: 将负类预测为正类数  10
-   TN: 将负类预测为负类数  30

**准确率**(accuracy) = 预测对的/所有 = (TP+TN)/(TP+FN+FP+TN) = 70%

**精确率**(precision) = TP/(TP+FP) = 80%

**召回率**(recall) = TP/(TP+FN) = 2/3

### 准确性 (业务角度)

如下，用户动作越多，说明越准确

![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810803.png)

### 覆盖度

-   信息熵 对于推荐越大越好，因为用户的流量不应该集中在某几件商品上，应该尽可能多样的推荐（熵越大，系统不确定性越高）
-   覆盖率

### 多样性&新颖性&惊喜性

-   多样性：推荐列表中两两物品的不相似性。（相似性如何度量？
-   新颖性：未曾关注的类别、作者；推荐结果的平均流⾏度
-   惊喜性：历史不相似（惊）但很满意（喜）
-   往往需要牺牲准确性
-   使⽤历史⾏为预测⽤户对某个物品的喜爱程度
-   系统过度强调实时性

### Exploitation & Exploration 探索与利用问题

-   Exploitation(开发 利用)：选择现在可能最佳的⽅案
-   Exploration(探测 搜索)：选择现在不确定的⼀些⽅案，但未来可能会有⾼收益的⽅案
-   在做两类决策的过程中，不断更新对所有决策的不确定性的认知，优化
    长期的⽬标

### EE问题实践

-   兴趣扩展: 相似话题, 搭配推荐
-   人群算法: userCF 用户聚类
-   平衡个性化推荐和热门推荐比例
-   随机丢弃用户行为历史
-   随机扰动模型参数

### EE可能带来的问题

-   探索伤害用户体验, 可能导致用户流失
-   探索带来的长期收益(留存率)评估周期长, KPI压力大
-   如何平衡实时兴趣和长期兴趣
-   如何平衡短期产品体验和长期系统生态
-   如何平衡大众口味和小众需求

### 评估方法

-   问卷调查: 有奖调查，成本高，可能损害用户体验（弹窗）
-   离线评估（RMSE、MSE等）:
    -   只能在用户看到过的候选集上做评估, 且跟线上真实效果存在偏差
    -   只能评估少数指标
    -   速度快, 不损害用户体验
-   在线评估: 灰度发布（后台控制10%或%5的流量访问按B策略，其余A策略） & A/B测试->如果效果好，适当的逐渐的增加B的比例->最后全量上线
-   实践: 离线评估和在线评估结合, 定期做问卷调查

# 推荐系统的冷启动问题

## 推荐系统冷启动概念

-   ⽤户冷启动：如何**为新⽤户做个性化推荐**
-   物品冷启动：如何**将新物品推荐给⽤户**（协同过滤）
-   系统冷启动：⽤户冷启动+物品冷启动（都是新来的）
-   **本质是推荐系统依赖历史数据，没有历史数据⽆法预测⽤户偏好**

## 用户冷启动

1.收集⽤户特征

⽤户注册信息：性别、年龄、地域

设备信息：定位、⼿机型号、app列表

社交信息、推⼴素材、安装来源
![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809993.png)

2 引导用户填写兴趣
![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041810712.png)

3 使用其它站点的行为数据, 例如腾讯视频&QQ音乐 今日头条&抖音（或者花钱买数据，不过可能存在法律问题）

4 新老用户推荐策略的差异

新⽤户在冷启动阶段更倾向于**热门排⾏榜**，⽼⽤户会更加需要**长尾推荐**

Explore Exploit⼒度

使⽤单独的特征和模型预估

举例 性别与电视剧的关系
![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809072.png)
![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809934.png)

**总的来说，用户冷启动，要尽可能收集用户信息，构建用户画像（打标签），根据用户的标签可以做人群聚类，用已有用户的行为做推荐，对新用户可以多推荐热门的东西**

## 物品冷启动

给物品打标签，构建物品画像

利用**物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户**。
![img](https://cdn.jsdelivr.net/gh/p0lar1star/blog-img/202204041809925.png)

## 系统冷启动

整个应用都是新的，没有数据收集

**如果应用缺少用户行为数据->基于内容的推荐（系统早期）**

**随着用户行为积累得越来越多->基于内容的推荐逐渐过渡到协同过滤，但不是把基于内容的推荐扔掉**

**基于内容的推荐和协同过滤的推荐结果都计算出来 加权求和得到最终推荐结果**

# 基于内容的推荐

## 给物品打标签

-   系统自己提取或从业务数据库中提取

-   用户填写

-   中文分词 利用算法**计算词的权重**

    -   **TF-IDF**

        TF：TermFrequency 词频 = 在当前一句话中出现的次数/一句话中的总词数，例如Python在一句话中出现了5次，这句话有100个词，则TF = 5 / 100

        IDF：逆文档频率 = lg(文本库篇数/出现关键词的文章篇数)

        如：1000篇文本中，出现Python关键字的有10篇，则该词的逆文档频率为lg100 = 2

        ∴TF-IDF= 5 / 100 * 2 = 0.1

    -   textrank

## 利用标签的文字 转换成词向量

-   word2Vec
-   用向量表示语义
-   词向量相似度高则词义相近

## 利用词向量 构建物品的向量

-   一个物品有N个关键词 每个关键词对应一个词向量
-   求和（权重*词向量）/ N
-   利用N个关键词的词向量获取物品向量

## 通过物品向量计算相似度

-   皮尔逊 相关系数

# 基于内容推荐和基于物品协同过滤区别

content_base：词向量->物品向量->计算相似度

item_based cf：user-item matrix->物品向量->相似度

区别在于：物品向量构建过程

-   基于内容推荐：物品向量来自于文本，这里的文本可能是物品的描述信息、系统自动打的标签和用户填的标签，依赖于物品本身，不需要用户参与自己就能搞定
-   基于物品协同过滤：从用户对物品的评分矩阵中来，也就是从**用户的行为数据**中来，依赖于用户行为数据，一定要收集一定量用户行为

# 总结

## 推荐模型构建流程

1.数据收集

显性评分、隐形数据

2.特征工程

协同过滤：用户-物品评分矩阵

基于内容：分词/标签->TF-IDF->word2vec得到词向量

3.训练模型

基于内存的协同过滤：kNN（没什么模型课训练的，拿到向量直接算相似度就可以了，根据相似度产生推荐结果）

基于模型的协同过滤：矩阵分解 梯度下降 求解出对应的系数之后套模型

为用户1推荐的过程（协同过滤）：从用户评分矩阵中找出与用户1相似的用户，去掉自己，过滤掉相似度小于等于0的用户（只留正相关），对这些相似用户购买过的商品逐一算出评分，取高分结果推荐给用户1